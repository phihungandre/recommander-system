{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m col\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mml\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pipeline\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Set plot parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 13)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données Train Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_training = pd.read_csv('./data/train_customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_users_training.describe(include=\"all\")\n",
    "#df_users_training.info(memory_usage=\"deep\")\n",
    "df_users_training[\"created_at\"] = pd.to_datetime(df_users_training[\"created_at\"])\n",
    "df_users_training[\"updated_at\"] = pd.to_datetime(df_users_training[\"updated_at\"])\n",
    "df_users_training.rename(columns={'akeed_customer_id': 'customer_id'}, inplace=True)\n",
    "\n",
    "# Drop useless columns\n",
    "df_users_training.drop(['language', 'dob', 'created_at'], axis=1, inplace=True)\n",
    "\n",
    "#make gender only two values\n",
    "df_users_training.gender.replace(to_replace=[r'[F|f].*', r'[M|m|?| ].*'], value=['F', 'M'], inplace=True, regex=True)\n",
    "\n",
    "#take only verified users\n",
    "df_users_training = df_users_training[df_users_training.verified == 1]\n",
    "\n",
    "# drop verified column and status column\n",
    "df_users_training.drop(['verified'], axis=1, inplace=True)\n",
    "df_users_training.drop(['status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données Train Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_users_loc_training = pd.read_csv('./data/train_locations.csv')\n",
    "#df_users_loc_training.describe(include=\"all\")\n",
    "#df_users_loc_training.info(memory_usage=\"deep\")\n",
    "# fill missing values from location_type\n",
    "df_users_loc_training.location_type.fillna('Other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données Train Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_orders = pd.read_csv('./data/orders.csv')\n",
    "#df_orders.describe(include='all')\n",
    "#df_orders.info(memory_usage=\"deep\")\n",
    "# lier avec customer_id, location_number et location_type\n",
    "df_orders.promo_code=df_orders.promo_code.fillna('', inplace=True)\n",
    "df_orders.promo_code=df_orders.promo_code.astype('bool')\n",
    "df_orders.promo_code_discount_percentage.fillna(0, inplace=True)\n",
    "df_orders.LOCATION_TYPE.fillna('Other', inplace=True)\n",
    "df_orders.drop(['delivery_time'], axis=1, inplace=True)\n",
    "df_orders.rename(columns={'LOCATION_TYPE': 'location_type'}, inplace=True)\n",
    "df_orders.rename(columns={'LOCATION_NUMBER': 'location_number'}, inplace=True)\n",
    "# Supprimer les lignes sans order_id\n",
    "# promo code important ? ou présence d'un promo code important\n",
    "# promo_code_discount_percentage > promo_code : promo_code_discount_percentage peut être à 0\n",
    "df_orders.is_favorite.fillna('', inplace=True)\n",
    "df_orders.is_favorite = df_orders.is_favorite.astype('bool')\n",
    "df_orders.is_favorite = df_orders.is_favorite.replace({True: 1, False: 0})\n",
    "df_orders.promo_code.fillna('', inplace=True)\n",
    "df_orders.promo_code = df_orders.promo_code.astype('bool')\n",
    "df_orders.promo_code = df_orders.promo_code.replace({True: 1, False: 0})\n",
    "df_orders.is_rated = df_orders.is_rated.replace({'No': 0, 'Yes': 1})\n",
    "df_orders.akeed_order_id = df_orders.akeed_order_id.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_training = pd.merge(df_users_training, df_users_loc_training, on='customer_id', how='left')\n",
    "df_users_training = df_users_training.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_training = pd.merge(df_users_training, df_orders, on=['customer_id', 'location_number', 'location_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_rating(distance, min_distance, max_distance, min_rating, max_rating):\n",
    "    # Normaliser la distance entre 0 et 1\n",
    "    normalized_distance = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "    # Convertir la distance normalisée en note\n",
    "    rating = normalized_distance * (max_rating - min_rating) + min_rating\n",
    "\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "distances = np.array([1.0, 2.0, 3.0])\n",
    "min_distance = 1.0\n",
    "max_distance = 3.0\n",
    "min_rating = 5.0 # Inverser l'ordre des notes\n",
    "max_rating = 1.0 # Inverser l'ordre des notes\n",
    "#create a column in df_merge_training with the rating\n",
    "df_merge_training['rating'] = distance_to_rating(df_merge_training.deliverydistance, df_merge_training.deliverydistance.min(), df_merge_training.deliverydistance.max(), min_rating, max_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_train = df_merge_training[['customer_id', 'location_number', 'vendor_id', 'rating']]\n",
    "df_matrix_train = df_matrix_train.assign(C=lambda x: x['customer_id'].astype(str) + ' X ' + x['location_number'].astype(str) + ' X ' + x['vendor_id'].astype(str))\n",
    "df_matrix_train.rename(columns={'C': 'CID X LOC_NUM X VENDOR', 'vendor_id': 'vendor'}, inplace=True)\n",
    "#remove duplicates\n",
    "df_matrix_train = df_matrix_train.drop_duplicates(subset=['CID X LOC_NUM X VENDOR'])\n",
    "df_matrix_train = df_matrix_train[['CID X LOC_NUM X VENDOR', 'vendor', 'rating']]\n",
    "df_matrix_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion de df_train en dataframe spark pour l'ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ALSMatrixFactorisation\").getOrCreate()\n",
    "\n",
    "df_training = spark.createDataFrame(df_matrix_train)\n",
    "df_training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(df_training.columns)-set(['rating'])) ]\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "df_training = pipeline.fit(df_training).transform(df_training)\n",
    "df_training.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données Test Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_test = pd.read_csv('./data/test_customers.csv')\n",
    "df_users_test.describe(include=\"all\")\n",
    "df_users_test.info(memory_usage=\"deep\")\n",
    "df_users_test[\"created_at\"] = pd.to_datetime(df_users_test[\"created_at\"])\n",
    "df_users_test[\"updated_at\"] = pd.to_datetime(df_users_test[\"updated_at\"])\n",
    "df_users_test.rename(columns={'akeed_customer_id': 'customer_id'}, inplace=True)\n",
    "\n",
    "# Drop useless columns\n",
    "df_users_test.drop(['language', 'dob', 'created_at'], axis=1, inplace=True)\n",
    "\n",
    "#make gender only two values\n",
    "df_users_test.gender.replace(to_replace=[r'[F|f].*', r'[M|m|?| ].*'], value=['F', 'M'], inplace=True, regex=True)\n",
    "\n",
    "#take only verified users\n",
    "df_users_test = df_users_test[df_users_test.verified == 1]\n",
    "\n",
    "\n",
    "# drop verified column and status column\n",
    "#df_users_test.drop(['verified'], axis=1, inplace=True)\n",
    "#df_users_test.drop(['status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données Test Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_loc_test = pd.read_csv('./data/test_locations.csv')\n",
    "df_users_loc_test.describe(include=\"all\")\n",
    "df_users_loc_test.info(memory_usage=\"deep\")\n",
    "# fill missing values from location_type\n",
    "df_users_loc_test.location_type.fillna('Other', inplace=True)\n",
    "#df_users_loc_test.location_type.fillna('Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_test = pd.merge(df_users_test, df_users_loc_test, on='customer_id', how='left')\n",
    "df_users_test.rename(columns={'customer_id_index': 'user_id','latitude':'latitude_user','longitude': 'longitude_user'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données Test Vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client = pd.read_csv('./data/vendors.csv')\n",
    "df_client = df_client[['id', 'latitude', 'longitude']]\n",
    "df_client.rename(columns={'id': 'vendor_id','latitude': 'latitude_vendor', 'longitude': 'longitude_vendor'}, inplace=True)\n",
    "df_matrix_test = pd.merge(df_users_test, df_client, how='cross')\n",
    "#show the first 20 rows\n",
    "df_matrix_test.head(20)\n",
    "df_matrix_test.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get deliverydistance and rating\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    # rayon de la terre en km\n",
    "    R = 6371\n",
    "\n",
    "    # conversion en radian\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    # formule\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * \\\n",
    "        np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    # distance en km\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_test['deliverydistance'] = distance(df_matrix_test.latitude_user, df_matrix_test.longitude_user, df_matrix_test.latitude_vendor, df_matrix_test.longitude_vendor)\n",
    "df_matrix_test['rating'] = distance_to_rating(df_matrix_test.deliverydistance, df_matrix_test.deliverydistance.min(), df_matrix_test.deliverydistance.max(), min_rating, max_rating)\n",
    "df_matrix_test= df_matrix_test[['customer_id','location_number','vendor_id','rating']]\n",
    "df_matrix_test = df_matrix_test.assign(C=lambda x: x['customer_id'].astype(str) + ' X ' + x['location_number'].astype(str) + ' X ' + x['vendor_id'].astype(str))\n",
    "df_matrix_test.rename(columns={'C': 'CID X LOC_NUM X VENDOR', 'vendor_id': 'vendor'}, inplace=True)\n",
    "#remove duplicates\n",
    "df_matrix_test = df_matrix_test.drop_duplicates(subset=['CID X LOC_NUM X VENDOR'])\n",
    "df_matrix_test = df_matrix_test[['CID X LOC_NUM X VENDOR', 'vendor', 'rating']]\n",
    "df_matrix_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion de df_test en dataframe spark pour l'ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = spark.createDataFrame(df_matrix_test)\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(df_test.columns)-set(['rating'])) ]\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "df_test = pipeline.fit(df_test).transform(df_test)\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    maxIter=5,\n",
    "    regParam=0.09,\n",
    "    rank=25,\n",
    "    userCol=\"CID X LOC_NUM X VENDOR_index\",\n",
    "    itemCol=\"vendor_index\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    ")\n",
    "\n",
    "model = als.fit(df_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "predictions = model.transform(df_test)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"RMSE=\" + str(rmse))\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommandation pour tous les utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recs = model.recommendForAllUsers(20).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
